{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":94995,"sourceType":"datasetVersion","datasetId":50852},{"sourceId":4164822,"sourceType":"datasetVersion","datasetId":2455438}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating, Reading and Writing","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:08.191502Z","iopub.execute_input":"2024-03-19T09:36:08.191928Z","iopub.status.idle":"2024-03-19T09:36:08.195122Z","shell.execute_reply.started":"2024-03-19T09:36:08.191901Z","shell.execute_reply":"2024-03-19T09:36:08.194430Z"}}},{"cell_type":"code","source":"# creating a dataframe\npd.DataFrame({'Raei':['Mess food is bad', 'Let\\'s go out'], 'Anmol':['It isn\\'t always that bad', 'But yes, let\\'s go out!']})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding index in place of default values 0, 1, 2, ...\npd.DataFrame({'Ravi':['Mess food is bad', 'Let\\'s go out'], 'Anmol':['It isn\\'t always that bad', 'Yes, let\\'s go out!']}, index=['No Biryani', 'Biryani'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating a series with user-defined indexes and name\npd.Series([1,2,3,4,5], index = ['Day 1','Day 2','Day 3','Day 4','Day 5'], name = 'Day Schedule')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reading an existing csv file for data\nwineReviews = pd.read_csv('/kaggle/input/winemagdata130kv3/winemag-data-130k-v2.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the number of rows and columns in the df\nwineReviews.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fetching the first five rows of the df\nwineReviews.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using the internal index present in csv in place of the one provided by pandas\nwineReviews = pd.read_csv('/kaggle/input/winemagdata130kv3/winemag-data-130k-v2.csv', index_col = 0)\nwineReviews.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Indexing, Selecting & Assigning","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:11.296519Z","iopub.execute_input":"2024-03-19T09:36:11.296926Z","iopub.status.idle":"2024-03-19T09:36:11.301290Z","shell.execute_reply.started":"2024-03-19T09:36:11.296897Z","shell.execute_reply":"2024-03-19T09:36:11.300194Z"}}},{"cell_type":"code","source":"# native accessors: using the object:accessor analogy like in book:title\n# wineReviews.country \n# or\nwineReviews['country']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# native accessors will not work if the column name contains special characters like a space so using the indexing operator is better\nwineReviews['country'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Indexing in Pandas\n\nPandas has its own accessor operators, loc and iloc, which are both row-first and column second as opposed to what we do in native python.\n\n-Index based selection: selecting data based on its numerical position in data","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:11.346714Z","iopub.execute_input":"2024-03-19T09:36:11.347121Z","iopub.status.idle":"2024-03-19T09:36:11.352398Z","shell.execute_reply.started":"2024-03-19T09:36:11.347087Z","shell.execute_reply":"2024-03-19T09:36:11.351237Z"}}},{"cell_type":"code","source":"# selecting the first three entries\nwineReviews.iloc[:3,0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# selecting only the second and third entry\nwineReviews.iloc[1:3,0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# passing a list of rows to retrieve\nwineReviews.iloc[[0,1,2],0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fetching the last 5 records\nwineReviews.iloc[-5:,0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-Label based selection: here data index value is important and not the position","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:11.414437Z","iopub.execute_input":"2024-03-19T09:36:11.414724Z","iopub.status.idle":"2024-03-19T09:36:11.424383Z","shell.execute_reply.started":"2024-03-19T09:36:11.414699Z","shell.execute_reply":"2024-03-19T09:36:11.423313Z"}}},{"cell_type":"code","source":"wineReviews.loc[0,'country']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"iloc is conceptually simpler than loc because it ignores the dataset's indices. When we use iloc we treat the dataset like a big matrix (a list of lists), one that we have to index into by position. loc, by contrast, uses the information in the indices to do its work. Since your dataset usually has meaningful indices, it's usually easier to do things using loc instead. For example, here's one operation that's much easier using loc:","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:11.427377Z","iopub.execute_input":"2024-03-19T09:36:11.427884Z","iopub.status.idle":"2024-03-19T09:36:11.448688Z","shell.execute_reply.started":"2024-03-19T09:36:11.427849Z","shell.execute_reply":"2024-03-19T09:36:11.447753Z"}}},{"cell_type":"code","source":"wineReviews.loc[:, ['taster_name', 'taster_twitter_handle', 'points']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Choosing between loc and iloc\n\nWhen choosing or transitioning between loc and iloc, there is one \"gotcha\" worth keeping in mind, which is that the two methods use slightly different indexing schemes. iloc uses the Python stdlib indexing scheme, where the first element of the range is included and the last one excluded. So 0:10 will select entries 0,...,9. loc, meanwhile, indexes inclusively. So 0:10 will select entries 0,...,10.","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:11.450491Z","iopub.execute_input":"2024-03-19T09:36:11.450873Z","iopub.status.idle":"2024-03-19T09:36:11.455258Z","shell.execute_reply.started":"2024-03-19T09:36:11.450838Z","shell.execute_reply":"2024-03-19T09:36:11.454121Z"}}},{"cell_type":"markdown","source":"Manipulating the index\n\nLabel-based selection derives its power from the labels in the index. Index are mutable and we can change them in any waywe see fitchanging the index of data","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:49:45.046629Z","iopub.execute_input":"2024-03-19T09:49:45.046988Z","iopub.status.idle":"2024-03-19T09:49:45.052281Z","shell.execute_reply.started":"2024-03-19T09:49:45.046960Z","shell.execute_reply":"2024-03-19T09:49:45.050452Z"}}},{"cell_type":"code","source":"wineReviews.set_index('title')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Conditional selection : Suppose that we're interested specifically in better-than-average wines produced in Italy.","metadata":{}},{"cell_type":"code","source":"wineReviews.country == 'Italy'\n# wineReviews.loc[:,'country']=='Italy'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select data with country = Italy\nwineReviews.loc[(wineReviews.country == 'Italy')]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using multiple conditions in loc\nwineReviews.loc[(wineReviews.country == 'Italy') & (wineReviews.points>=90)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using multiple conditions in loc\nwineReviews.loc[(wineReviews.country == 'Italy') | (wineReviews.points>=90)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using builtin conditional selectors:\n1. isin: selects data whose value \"is in\" a list of values","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:50:43.061541Z","iopub.execute_input":"2024-03-19T09:50:43.061924Z","iopub.status.idle":"2024-03-19T09:50:43.098891Z","shell.execute_reply.started":"2024-03-19T09:50:43.061891Z","shell.execute_reply":"2024-03-19T09:50:43.097887Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"wineReviews.loc[wineReviews.country.isin(['Italy','France'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. isnull (or nornull): selects values which are (or are not) empty (NaN)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:50:47.150718Z","iopub.execute_input":"2024-03-19T09:50:47.151088Z","iopub.status.idle":"2024-03-19T09:50:47.203042Z","shell.execute_reply.started":"2024-03-19T09:50:47.151059Z","shell.execute_reply":"2024-03-19T09:50:47.201806Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"wineReviews.loc[wineReviews.price.notnull()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Assigning data","metadata":{}},{"cell_type":"code","source":"wineReviews['critic'] = 'everyone'\nwineReviews['critic']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# or using an iterable value\nwineReviews['index_backwards'] = range(len(wineReviews), 0, -1)\nwineReviews['index_backwards']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary Functions and Maps","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:11.772231Z","iopub.execute_input":"2024-03-19T09:36:11.772494Z","iopub.status.idle":"2024-03-19T09:36:11.777526Z","shell.execute_reply.started":"2024-03-19T09:36:11.772471Z","shell.execute_reply":"2024-03-19T09:36:11.776583Z"}}},{"cell_type":"markdown","source":"Summary functions: Pandas provides many simple \"summary functions\" (not an official name) which restructure the data in some useful way describe() is type-aware and gives relevant output.","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:11.778809Z","iopub.execute_input":"2024-03-19T09:36:11.779256Z","iopub.status.idle":"2024-03-19T09:36:11.801907Z","shell.execute_reply.started":"2024-03-19T09:36:11.779230Z","shell.execute_reply":"2024-03-19T09:36:11.800825Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"wineReviews.loc[:,'points'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wineReviews.taster_name.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the mean() of points\nwineReviews.points.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# finding unique values\nwineReviews.taster_name.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"List of unique values and how often they occur in the dataset, we can use the value_counts() method:","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:11.857529Z","iopub.execute_input":"2024-03-19T09:36:11.857821Z","iopub.status.idle":"2024-03-19T09:36:11.876513Z","shell.execute_reply.started":"2024-03-19T09:36:11.857795Z","shell.execute_reply":"2024-03-19T09:36:11.875509Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"wineReviews.taster_name.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Maps: A map is a term, borrowed from mathematics, for a function that takes one set of values and \"maps\" them to another set of values. In data science we often have a need for creating new representations from existing data, or for transforming data from the format it is in now to the format that we want it to be in later. ","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:11.878079Z","iopub.execute_input":"2024-03-19T09:36:11.878346Z","iopub.status.idle":"2024-03-19T09:36:11.885016Z","shell.execute_reply.started":"2024-03-19T09:36:11.878323Z","shell.execute_reply":"2024-03-19T09:36:11.884184Z"}}},{"cell_type":"markdown","source":"1. Maps: map() is the first, and slightly simpler one. ","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:11.886328Z","iopub.execute_input":"2024-03-19T09:36:11.886593Z","iopub.status.idle":"2024-03-19T09:36:11.956965Z","shell.execute_reply.started":"2024-03-19T09:36:11.886570Z","shell.execute_reply":"2024-03-19T09:36:11.955828Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"# For example, suppose that we wanted to remean the scores the wines received to 0. We can do this as follows:\nmean_points = wineReviews.points.mean()\n \n#lambda functions are used to apply simple functions fastly on a series/dataframe\nwineReviews.points.map(lambda p:p-mean_points)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Apply: apply() is the equivalent method if we want to transform a whole DataFrame by calling a custom method on each row.","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:11.959793Z","iopub.execute_input":"2024-03-19T09:36:11.960132Z","iopub.status.idle":"2024-03-19T09:36:24.801206Z","shell.execute_reply.started":"2024-03-19T09:36:11.960103Z","shell.execute_reply":"2024-03-19T09:36:24.800096Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"def apply_mean_points(row):\n    row.points = row.points - mean_points\n    return row\nwineReviews.apply(apply_mean_points, axis = 'columns')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note that map() and apply() return new, transformed Series and DataFrames, respectively. They don't modify the original data they're called on.\nwineReviews.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pandas provides many common mapping operations as built-ins. For example, here's a faster way of remeaning our points column:","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:24.822181Z","iopub.execute_input":"2024-03-19T09:36:24.822794Z","iopub.status.idle":"2024-03-19T09:36:24.833835Z","shell.execute_reply.started":"2024-03-19T09:36:24.822763Z","shell.execute_reply":"2024-03-19T09:36:24.832635Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"wineReviews.points - mean_points\nwineReviews.points","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The original data is preserved In this code we are performing an operation between a lot of values on the left-hand side (everything in the Series) and a single value on the right-hand side (the mean value). Pandas looks at this expression and figures out that we must mean to subtract that mean value from every value in the dataset.","metadata":{}},{"cell_type":"markdown","source":"Pandas will also understand what to do if we perform these operations between Series of equal length. For example, an easy way of combining country and region information in the dataset would be to do the following:","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:24.834934Z","iopub.execute_input":"2024-03-19T09:36:24.835247Z","iopub.status.idle":"2024-03-19T09:36:24.888717Z","shell.execute_reply.started":"2024-03-19T09:36:24.835221Z","shell.execute_reply":"2024-03-19T09:36:24.887802Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"wineReviews.country + \" - \" + wineReviews.region_1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finding the wine with the best point/price ratio","metadata":{}},{"cell_type":"code","source":"bargain_idx = (wineReviews.points / wineReviews.price).idxmax()\nbargain_wine = wineReviews.loc[bargain_idx, 'title']\nbargain_wine","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grouping and Sorting","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:24.900850Z","iopub.execute_input":"2024-03-19T09:36:24.901516Z","iopub.status.idle":"2024-03-19T09:36:24.905751Z","shell.execute_reply.started":"2024-03-19T09:36:24.901489Z","shell.execute_reply":"2024-03-19T09:36:24.904798Z"}}},{"cell_type":"markdown","source":"Maps allow us to transform data in a DataFrame or Series one value at a time for an entire column. However, often we want to group our data, and then do \nsomething specific to the group the data is in. As you'll learn, we do this with the groupby() operation.","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:36:24.906986Z","iopub.execute_input":"2024-03-19T09:36:24.907332Z","iopub.status.idle":"2024-03-19T09:36:24.916324Z","shell.execute_reply.started":"2024-03-19T09:36:24.907305Z","shell.execute_reply":"2024-03-19T09:36:24.915514Z"}}},{"cell_type":"markdown","source":"Groupwise analysis:\nOne function we've been using heavily thus far is the value_counts() function. We can replicate what value_counts() does by doing the following:","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:40:05.097112Z","iopub.execute_input":"2024-03-19T09:40:05.097480Z","iopub.status.idle":"2024-03-19T09:40:05.109489Z","shell.execute_reply.started":"2024-03-19T09:40:05.097452Z","shell.execute_reply":"2024-03-19T09:40:05.107843Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"wineReviews.groupby('points').points.count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to get the cheapest wine in each point category, we can use the following code snippet\nwineReviews.groupby('points').price.min()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can think of each group we generate as being a slice of our DataFrame containing only data with values that match. This DataFrame is accessible to us directly using the apply() method, and we can then manipulate the data in any way we see fit. For example, here's one way of selecting the name of the first wine reviewed from each winery in the dataset:","metadata":{}},{"cell_type":"code","source":"wineReviews.groupby('winery').apply(lambda df:df.title.iloc[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For even more fine-grained control, you can also group by more than one column. For an example, here's how we would pick out the best wine by country and province:","metadata":{}},{"cell_type":"code","source":"wineReviews.groupby(['country', 'province']).apply(lambda df : df.loc[df.points.idxmax()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another groupby() method worth mentioning is agg(), which lets you run a bunch of different functions on your DataFrame simultaneously. For example, we can generate a simple statistical summary of the dataset as follows:","metadata":{}},{"cell_type":"code","source":"wineReviews.groupby('country').price.agg([len, min, max])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sorting: Grouping returns data in index order, not in value order. The order of the rows is dependent on the values in the index, not in the data. To get data in the order want it in we can sort it ourselves. The sort_values() method is handy for this.","metadata":{}},{"cell_type":"code","source":"countries_reviewed = wineReviews.groupby(['country', 'province']).description.agg([len])\ncountries_reviewed\n# prints countries based on their country and province, ignoring the order in which they appear in the dataframe","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"countries_reviewed = countries_reviewed.reset_index()   #resetting the order back to how it was in the dataframe\ncountries_reviewed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sorting the wines based on how many times a country name appears\ncountries_reviewed.sort_values(by='len', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To sort by index values, use the companion method sort_index(). This method has the same arguments and default order:","metadata":{}},{"cell_type":"code","source":"countries_reviewed.sort_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sort by more than one column at a time:","metadata":{}},{"cell_type":"code","source":"countries_reviewed.sort_values(by=['country','len'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Types and Missing Values","metadata":{}},{"cell_type":"markdown","source":"In this tutorial, you'll learn how to investigate data types within a DataFrame or Series. You'll also learn how to find and replace entries.\n\nDtypes\nThe data type for a column in a DataFrame or a Series is known as the dtype.\nYou can use the dtype property to grab the type of a specific column.","metadata":{}},{"cell_type":"code","source":"wineReviews.price.dtype  # returns the dtype of price column\nwineReviews.dtypes  # returns the dtype of each column in the dataframe","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One peculiarity to keep in mind (and on display very clearly here) is that columns consisting entirely of strings do not get their own type; they are instead given the object type.","metadata":{}},{"cell_type":"markdown","source":"It's possible to convert a column of one type into another wherever such a conversion makes sense by using the astype() function.","metadata":{}},{"cell_type":"code","source":"wineReviews.points.astype('float64')  # converts the dtype of points from int64 to float64","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A dataframe or series index has its own dtype","metadata":{}},{"cell_type":"code","source":"wineReviews.index.dtype","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Missing data: Entries missing values are given the value NaN, short for \"Not a Number\". For technical reasons these NaN values are always of the float64 dtype.\nPandas provides some methods specific to missing data. To select NaN entries you can use pd.isnull() (or its companion pd.notnull()). ","metadata":{}},{"cell_type":"code","source":"wineReviews[pd.isnull(wineReviews.country)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Replacing missing values is a common operation. Pandas provides a really handy method for this problem: fillna(). fillna() provides a few different strategies for mitigating such data. For example, we can simply replace each NaN with an \"Unknown\":","metadata":{}},{"cell_type":"code","source":"wineReviews.region_2.fillna(\"Unknown\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Or we could fill each missing value with the first non-null value that appears sometime after the given record in the database. This is known as the backfill strategy.","metadata":{}},{"cell_type":"markdown","source":"Alternatively, we may have a non-null value that we would like to replace. For example, suppose that since this dataset was published, reviewer Kerin O'Keefe has changed her Twitter handle from @kerinokeefe to @kerino. One way to reflect this in the dataset is using the replace() method:","metadata":{}},{"cell_type":"code","source":"wineReviews.taster_twitter_handle.replace(\"@kerinokeefe\", \"@kerino\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The replace() method is worth mentioning here because it's handy for replacing missing data which is given some kind of sentinel value in the dataset: things like \"Unknown\", \"Undisclosed\", \"Invalid\", and so on.","metadata":{}},{"cell_type":"markdown","source":"# Renaming and Combining","metadata":{}},{"cell_type":"markdown","source":"Oftentimes data will come to us with column names, index names, or other naming conventions that we are not satisfied with. In that case, you'll learn how to use pandas functions to change the names of the offending entries to something better.\nYou'll also explore how to combine data from multiple DataFrames and/or Series.","metadata":{}},{"cell_type":"markdown","source":"Renaming: The first function we'll introduce here is rename(), which lets you change index names and/or column names. For example, to change the points column in our dataset to score, we would do:","metadata":{}},{"cell_type":"code","source":"wineReviews.rename(columns={'points':'score'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"rename() lets you rename index or column values by specifying a index or column keyword parameter, respectively. It supports a variety of input formats, but usually a Python dictionary is the most convenient. Here is an example using it to rename some elements of the index.","metadata":{}},{"cell_type":"code","source":"wineReviews.rename(index={0:'first', 1:'second'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You'll probably rename columns very often, but rename index values very rarely. For that, set_index() is usually more convenient.\nBoth the row index and the column index can have their own name attribute. The complimentary rename_axis() method may be used to change these names. ","metadata":{}},{"cell_type":"code","source":"# we change the name of the axes, from 0 and 1 to \"wines\" and \"fields\"\nwineReviews.rename_axis(\"wines\", axis='rows').rename_axis(\"fields\", axis='columns')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Combining: When performing operations on a dataset, we will sometimes need to combine different DataFrames and/or Series in non-trivial ways. Pandas has three core methods for doing this. In order of increasing complexity, these are concat(), join(), and merge(). Most of what merge() can do can also be done more simply with join(), so we will omit it and focus on the first two functions here.","metadata":{}},{"cell_type":"markdown","source":"The simplest combining method is concat(). Given a list of elements, this function will smush those elements together along an axis.","metadata":{}},{"cell_type":"code","source":"canadian_youtube = pd.read_csv(\"/kaggle/input/youtube-dataset-of-countries/Youtube_data/Countries_data/CAvideos.csv\")\nbritish_youtube = pd.read_csv(\"/kaggle/input/youtube-dataset-of-countries/Youtube_data/Countries_data/GBvideos.csv\")\npd.concat([canadian_youtube, british_youtube])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The middlemost combiner in terms of complexity is join(). join() lets you combine different DataFrame objects which have an index in common. For example, to pull down videos that happened to be trending on the same day in both Canada and the UK, we could do the following:","metadata":{}},{"cell_type":"code","source":"left = canadian_youtube.set_index(['title', 'trending_date'])\nright = british_youtube.set_index(['title', 'trending_date'])\nleft.join(right, lsuffix='_CAN', rsuffix='_UK')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The lsuffix and rsuffix parameters are necessary here because the data has the same column names in both British and Canadian datasets. If this wasn't true (because, say, we'd renamed them beforehand) we wouldn't need them.","metadata":{}}]}